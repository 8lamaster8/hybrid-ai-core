#!/usr/bin/env python3
"""
ü§ñ AUTONOMOUS AI PRODUCTION READY SYSTEM v3.1
–ü–æ–ª–Ω–æ—Å—Ç—å—é –ª–æ–∫–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞, —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏, –≥—Ä–∞—Ñ–æ–º, –∫–æ–º–∏—Ç–µ—Ç–æ–º, –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–º, ENGRAM
–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è: NER, RankingService, —É–º–Ω–æ–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤
"""

import os
import sys
import asyncio
import traceback
import yaml
from datetime import datetime
import time

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, BASE_DIR)

# Core
from appp.core.config import Config
from appp.core.logging import setup_logging, get_logger

# Services
from appp.services.detective.detective import Detective
from appp.services.committee.quality_committee import QualityCommittee
from appp.services.analyst.knowledge_analyst import KnowledgeAnalyst
from appp.services.interviewer.question_generator import QuestionGenerator
from appp.services.storage.chroma_db import ChromaDBService
from appp.services.storage.networkx_graph import NetworkXGraphService
from appp.services.storage.engram_db import EngramService
from appp.services.embedding.bge_m3 import BGE_M3_Embedder
from appp.services.embedding.bge_m3 import embedder as global_embedder
from appp.core.logging import logger

# Coordination
from appp.coordination.service_coordinator import ServiceCoordinator, get_coordinator
from appp.coordination.learning_coordinator import LearningCycleCoordinator, get_learning_coordinator
from appp.utils.response_templates import RESPONSE_TEMPLATES, format_rich_response


logger = get_logger('AutonomousAI')


class AutonomousAIPro:
    def __init__(self, config_path: str = None):
        self.config = Config.load(config_path)

        self.coordinator = None
        self.detective = None
        self.committee = None
        self.analyst = None
        self.interviewer = None
        self.chroma_db = None
        self.graph_db = None
        self.engram = None
        self.embedder = None
        self.learning_coordinator = None
        self.learning_task = None

        self.is_initialized = False
        self.is_running = False

        self.session_stats = {
            'start_time': None,
            'questions_asked': 0,
            'research_done': 0,
            'learning_cycles': 0,
            'errors': 0
        }

        logger.info("ü§ñ AutonomousAIPro –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    # ----- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤–≤–æ–¥ (—á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop) -----
    async def ainput(self, prompt: str = "") -> str:
        return await asyncio.to_thread(input, prompt)

    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã...")

        try:
            # 1. –≠–º–±–µ–¥–¥–∏–Ω–≥–∏
            logger.info("1/8 üß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
            self.embedder = BGE_M3_Embedder(
                model_name=self.config.embedding.model_name,
                model_path=self.config.embedding.model_path,
                device=self.config.embedding.device,
                normalize_embeddings=self.config.embedding.normalize_embeddings,
                cache_dir=self.config.embedding.cache_dir,
                max_cache_size=self.config.embedding.max_cache_size,
                batch_size=self.config.embedding.batch_size,
                embedding_dimension=self.config.embedding.embedding_dimension
            )
            embedder_ok = await self.embedder.initialize()

            # !!! –í–ê–ñ–ù–û: –ø–µ—Ä–µ–Ω–∞–∑–Ω–∞—á–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π embedder –≤ –º–æ–¥—É–ª–µ !!!
            import appp.services.embedding.bge_m3 as bge_module
            bge_module.embedder = self.embedder
            logger.info("   ‚úÖ –ì–ª–æ–±–∞–ª—å–Ω—ã–π embedder –º–æ–¥—É–ª—è bge_m3 –∑–∞–º–µ–Ω—ë–Ω")

            if not embedder_ok:
                logger.warning("‚ö†Ô∏è –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, ChromaDB –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
            else:
                # –ü–µ—Ä–µ–Ω–∞–∑–Ω–∞—á–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π embedder –¥–ª—è RankingService –∏ –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª–µ–π
                global_embedder = self.embedder
                logger.info("   ‚úÖ –ì–ª–æ–±–∞–ª—å–Ω—ã–π embedder –ø–µ—Ä–µ–Ω–∞–∑–Ω–∞—á–µ–Ω")

            # 2. –•—Ä–∞–Ω–∏–ª–∏—â–∞
            logger.info("2/8 üíæ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏–ª–∏—â...")

            # ChromaDB (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç–º–±–µ–¥–¥–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω)
            if embedder_ok and self.embedder.model is not None:
                self.chroma_db = ChromaDBService(
                    persist_directory=self.config.storage.chroma_path,
                    embedding_function=self.embedder.get_embedding_function(),
                    collection_name="knowledge_embeddings",
                    max_collection_size=self.config.storage.max_chroma_records
                )
                await self.chroma_db.initialize()
                logger.info("   ‚úÖ ChromaDB –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            else:
                self.chroma_db = None
                logger.warning("   ‚ö†Ô∏è ChromaDB –æ—Ç–∫–ª—é—á–µ–Ω–∞ (–Ω–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)")

            # NetworkX –≥—Ä–∞—Ñ
            self.graph_db = NetworkXGraphService(
                db_path=self.config.storage.graph_path,
                auto_save=self.config.storage.auto_save,
                save_interval=self.config.storage.save_interval
            )
            await self.graph_db.initialize()

            # üß† Engram –ø–∞–º—è—Ç—å
            logger.info("   üß† –ó–∞–≥—Ä—É–∑–∫–∞ Engram –ø–∞–º—è—Ç–∏...")
            try:
                self.engram = EngramService(
                    db_path=self.config.storage.engram_path,
                    max_records=self.config.storage.max_engram_records
                )
                await self.engram.initialize()
                logger.info("   ‚úÖ Engram –ø–∞–º—è—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è EngramService –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                self.engram = None

            # 3. –î–µ—Ç–µ–∫—Ç–∏–≤
            logger.info("3/8 üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CURL –¥–µ—Ç–µ–∫—Ç–∏–≤–∞...")
            detective_config = {
                'search_engine': self.config.detective.search_engine,
                'max_pages_per_topic': self.config.detective.max_pages_per_topic,
                'max_results_per_page': self.config.detective.max_results_per_page,
                'min_content_length': self.config.detective.min_content_length,
                'max_content_length': self.config.detective.max_content_length,
                'timeout': self.config.detective.timeout,
                'user_agent': self.config.detective.user_agent,
                'proxies': self.config.detective.proxies,
                'retry_attempts': self.config.detective.retry_attempts,
                'blacklist_domains': self.config.detective.blacklist_domains,
                'priority_domains': getattr(self.config.detective, 'priority_domains', [])
            }
            self.detective = Detective(detective_config)
            await self.detective.initialize()

            # 4. –ö–æ–º–∏—Ç–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞
            logger.info("4/8 ‚öñÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–∏—Ç–µ—Ç–∞ –∫–∞—á–µ—Å—Ç–≤–∞...")
            committee_config = {
                'min_relevance_score': self.config.committee.min_relevance_score,
                'min_quality_score': self.config.committee.min_quality_score,
                'min_uniqueness_score': self.config.committee.min_uniqueness_score,
                'blocked_keywords': self.config.committee.blocked_keywords,
                'enable_embedding_check': self.config.committee.enable_embedding_check,
                'embedding_threshold': self.config.committee.embedding_threshold,
                'min_sentences': self.config.committee.min_sentences,
                'language': self.config.committee.language
            }
            self.committee = QualityCommittee(committee_config)
            await self.committee.initialize()

            # --- –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–æ–≤ –¥–æ–º–µ–Ω–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏–∑ quality.yaml ---
            priority_domains = []
            low_trust_domains = []
            quality_config_path = os.path.join(BASE_DIR, 'configs', 'quality.yaml')
            if os.path.exists(quality_config_path):
                try:
                    with open(quality_config_path, 'r', encoding='utf-8') as f:
                        qc = yaml.safe_load(f)
                        priority_domains = qc.get('priority_domains', [])
                        low_trust_domains = qc.get('low_trust_domains', [])
                    logger.info(f"üìÅ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–æ–º–µ–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö {len(priority_domains)}, –Ω–∏–∑–∫–æ–≥–æ –¥–æ–≤–µ—Ä–∏—è {len(low_trust_domains)}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å quality.yaml: {e}")

            # 5. –ê–Ω–∞–ª–∏—Ç–∏–∫ –∑–Ω–∞–Ω–∏–π (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π NER –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è)
            logger.info("5/8 üìö –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∑–Ω–∞–Ω–∏–π...")
            analyst_config = {
                'chunk_size': self.config.analyst.chunk_size,
                'chunk_overlap': self.config.analyst.chunk_overlap,
                'min_chunk_length': self.config.analyst.min_chunk_length,
                'max_chunks_per_document': self.config.analyst.max_chunks_per_document,
                'extraction_strategy': self.config.analyst.extraction_strategy,
                'enable_summarization': self.config.analyst.enable_summarization,
                'summary_length': self.config.analyst.summary_length,
                'enable_entity_extraction': self.config.analyst.enable_entity_extraction,
                'enable_relation_extraction': self.config.analyst.enable_relation_extraction,
                'language': self.config.analyst.language,
                'min_confidence': self.config.analyst.min_confidence,
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –∏ NER
                'enable_ner': True,
                'priority_domains': priority_domains,
                'low_trust_domains': low_trust_domains
            }
            self.analyst = KnowledgeAnalyst(analyst_config)
            await self.analyst.initialize()

            # 6. –ò–Ω—Ç–µ—Ä–≤—å—é–µ—Ä (—Å –ø–µ—Ä–µ–¥–∞—á–µ–π graph_db –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ–º)
            logger.info("6/8 üé§ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞...")
            interviewer_config = {
                'max_questions_per_topic': getattr(self.config, 'max_questions_per_topic', 15),
                'question_depth_levels': getattr(self.config, 'question_depth_levels', 3),
                'enable_followup_questions': getattr(self.config, 'enable_followup_questions', True),
                'question_types': getattr(self.config, 'question_types', ['factual', 'comparative', 'causal', 'procedural']),
                'min_question_quality': getattr(self.config, 'min_question_quality', 0.6),
                'language': self.config.committee.language
            }
            self.interviewer = QuestionGenerator(interviewer_config, graph_db=self.graph_db)
            await self.interviewer.initialize()

            # 7. –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä —Å–µ—Ä–≤–∏—Å–æ–≤
            logger.info("7/8 üéØ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–∞ —Å–µ—Ä–≤–∏—Å–æ–≤...")
            self.coordinator = ServiceCoordinator(
                self.config,
                detective=self.detective,
                committee=self.committee,
                analyst=self.analyst,
                interviewer=self.interviewer,
                chroma_db=self.chroma_db,
                graph_db=self.graph_db,
                engram=self.engram,
                embedder=self.embedder
            )
            await self.coordinator.initialize()

            # 8. –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è
            logger.info("8/8 üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è...")
            if self.config.learning.enabled:
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å —Å–µ—Ä–≤–∏—Å–æ–≤ –¥–ª—è —Ü–∏–∫–ª–æ–≤
                learning_services = {
                    'detective': self.detective,
                    'committee': self.committee,
                    'analyst': self.analyst,
                    'interviewer': self.interviewer,
                    'chroma_db': self.chroma_db,
                    'graph_db': self.graph_db,
                    'engram': self.engram,
                    'embedder': self.embedder
                }

                # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ü–∏–∫–ª–æ–≤ (–±–µ—Ä—ë–º –∏–∑ self.config.learning)
                learning_config = {
                    'enabled': self.config.learning.enabled,
                    'check_interval': self.config.learning.check_interval,
                    'priorities': self.config.learning.priorities,
                    'intervals': self.config.learning.intervals,
                    'cycles': self.config.learning.cycles
                }

                self.learning_coordinator = LearningCycleCoordinator(learning_services, learning_config)

                # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
                self.learning_task = asyncio.create_task(
                    self.learning_coordinator.start(),
                    name="learning_coordinator"
                )

                # –î–æ–±–∞–≤–ª—è–µ–º callback –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –æ—à–∏–±–æ–∫
                def learning_task_done(task):
                    try:
                        task.result()
                    except asyncio.CancelledError:
                        logger.info("Learning task was cancelled")
                    except Exception as e:
                        logger.error(f"‚ùå Learning task crashed: {e}", exc_info=True)

                self.learning_task.add_done_callback(learning_task_done)
                logger.info("   ‚úÖ –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –∑–∞–ø—É—â–µ–Ω")
            else:
                logger.info("   ‚ö†Ô∏è –°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")

            self.is_initialized = True
            self.session_stats['start_time'] = datetime.now()

            logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}", exc_info=True)
            return False

    # ---------- –ü—É–±–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã ----------
    async def ask_question(self, question: str) -> dict:
        if not self.is_initialized:
            return {'error': '–°–∏—Å—Ç–µ–º–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞'}
        logger.info(f"‚ùì –í–æ–ø—Ä–æ—Å: {question}")
        self.session_stats['questions_asked'] += 1

        task_data = {
            'type': 'simple_question',
            'question': question,
            'priority': 1
        }
        task_id = await self.coordinator.submit_task(task_data)

        timeout = self.config.coordinator.task_timeout
        start_wait = time.time()
        while time.time() - start_wait < timeout:
            await asyncio.sleep(0.5)
            task_status = await self.coordinator.get_task_status(task_id)
            if task_status['status'] in ['completed', 'failed']:
                return task_status.get('result', {})
        return {'error': f'–¢–∞–π–º–∞—É—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞ (>{timeout} —Å–µ–∫)'}

    async def research_topic(self, topic: str, depth: int = 2) -> dict:
        self.session_stats['research_done'] += 1
        task_data = {
            'type': 'deep_research',
            'topic': topic,
            'depth': depth,
            'priority': 1
        }
        task_id = await self.coordinator.submit_task(task_data)
        for _ in range(60):
            await asyncio.sleep(1)
            task_status = await self.coordinator.get_task_status(task_id)
            if task_status['status'] in ['completed', 'failed']:
                return task_status.get('result', {})
        return {'error': '–¢–∞–π–º–∞—É—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è'}

    async def explore_topic(self, topic: str) -> dict:
        task_data = {
            'type': 'topic_exploration',
            'topic': topic,
            'max_cycles': 3,
            'priority': 1
        }
        task_id = await self.coordinator.submit_task(task_data)
        for _ in range(120):
            await asyncio.sleep(1)
            task_status = await self.coordinator.get_task_status(task_id)
            if task_status['status'] in ['completed', 'failed']:
                return task_status.get('result', {})
        return {'error': '–¢–∞–π–º–∞—É—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è'}

    async def self_learn(self) -> dict:
        """–†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è (—Å–ª—É—á–∞–π–Ω—ã–π —Ç–∏–ø)."""
        self.session_stats['learning_cycles'] += 1
        if not self.learning_coordinator:
            return {'error': '–°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ'}

        import random
        cycle_type = random.choice(list(self.learning_coordinator.cycles.keys()))
        result = await self.learning_coordinator.run_cycle(cycle_type)
        return {
            'success': True,
            'message': f'–ó–∞–ø—É—â–µ–Ω —Ü–∏–∫–ª {cycle_type.value}',
            'result': result
        }

    async def get_learning_stats(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è."""
        if self.learning_coordinator:
            return self.learning_coordinator.get_stats()
        return {'enabled': False, 'message': 'Learning coordinator not running'}

    async def get_system_status(self) -> dict:
        if not self.is_initialized:
            return {'initialized': False}

        metrics = await self.coordinator.get_system_metrics()
        status = {
            'initialized': self.is_initialized,
            'running': self.is_running,
            'session': self.session_stats,
            'uptime_seconds': (datetime.now() - self.session_stats['start_time']).total_seconds() if self.session_stats['start_time'] else 0,
            'coordinator': metrics.get('coordinator', {}),
            'detective': await self.detective.get_stats() if self.detective else {},
            'committee': await self.committee.get_stats() if self.committee else {},
            'analyst': await self.analyst.get_analyst_stats() if self.analyst else {},
            'interviewer': await self.interviewer.get_stats() if self.interviewer else {},
            'chroma': await self.chroma_db.get_detailed_stats() if self.chroma_db else {},
            'graph': await self.graph_db.get_stats() if self.graph_db else {},
            'engram': await self.engram.get_stats() if self.engram else {},
            'embedder': await self.embedder.get_metrics() if self.embedder else {}
        }
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è, –µ—Å–ª–∏ –µ—Å—Ç—å
        if self.learning_coordinator:
            status['learning'] = self.learning_coordinator.get_stats()
        return status

    # ---------- –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º ----------
    async def interactive_mode(self):
        print("\n" + "=" * 80)
        print("ü§ñ AUTONOMOUS AI PRO - –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –†–ï–ñ–ò–ú")
        print("=" * 80)
        print("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:")
        print("   ‚Ä¢ –≤–æ–ø—Ä–æ—Å <—Ç–µ–∫—Å—Ç>     - –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å")
        print("   ‚Ä¢ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å <—Ç–µ–º–∞> - –≥–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ")
        print("   ‚Ä¢ —Ü–∏–∫–ª <—Ç–µ–º–∞>        - –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å —Ü–∏–∫–ª–∞–º–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç")
        print("   ‚Ä¢ –æ–±—É—á–∏—Ç—å—Å—è          - –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ (–æ–¥–∏–Ω —Ü–∏–∫–ª)")
        print("   ‚Ä¢ —Å—Ç–∞—Ç—É—Å_–æ–±—É—á–µ–Ω–∏—è    - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è")
        print("   ‚Ä¢ —Å—Ç–∞—Ç—É—Å             - —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã")
        print("   ‚Ä¢ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞         - –ø–æ–¥—Ä–æ–±–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        print("   ‚Ä¢ –≤—ã—Ö–æ–¥              - –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã")
        print("\n" + "=" * 80)

        while True:
            try:
                # –î–∞—ë–º –Ω–µ–±–æ–ª—å—à—É—é –ø–∞—É–∑—É, —á—Ç–æ–±—ã —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –º–æ–≥–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å—Å—è –ø–µ—Ä–µ–¥ –≤–≤–æ–¥–æ–º
                await asyncio.sleep(0.1)
                user_input = (await self.ainput("\nüéØ > ")).strip()

                if not user_input:
                    continue
                if user_input.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit', 'q']:
                    print("üëã –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
                    break
                elif user_input.lower() in ['—Å—Ç–∞—Ç—É—Å', 'status']:
                    status = await self.get_system_status()
                    self._display_status(status)
                elif user_input.lower() in ['—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', 'stats']:
                    status = await self.get_system_status()
                    self._display_detailed_stats(status)
                elif user_input.lower() in ['–æ–±—É—á–∏—Ç—å—Å—è', '–æ–±—É—á–µ–Ω–∏–µ', 'learn']:
                    print("üß† –ó–∞–ø—É—Å–∫ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è...")
                    result = await self.self_learn()
                    print(f"‚úÖ {result.get('message')}")
                    if 'result' in result:
                        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result['result']}")
                elif user_input.lower() in ['—Å—Ç–∞—Ç—É—Å_–æ–±—É—á–µ–Ω–∏—è', 'learning_stats']:
                    stats = await self.get_learning_stats()
                    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è:")
                    for key, val in stats.items():
                        print(f"   {key}: {val}")
                elif user_input.lower().startswith('–≤–æ–ø—Ä–æ—Å '):
                    question = user_input[7:].strip()
                    if question:
                        print(f"‚ùì –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {question}")
                        result = await self.ask_question(question)
                        self._display_answer(result)
                    else:
                        print("‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")
                elif user_input.lower().startswith('–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å '):
                    topic = user_input[12:].strip()
                    if topic:
                        print(f"üîç –ì–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ: {topic}")
                        result = await self.research_topic(topic, depth=2)
                        self._display_research(result)
                    else:
                        print("‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ —Ç–µ–º—É")
                elif user_input.lower().startswith('—Ü–∏–∫–ª '):
                    topic = user_input[5:].strip()
                    if topic:
                        print(f"üåÄ –¶–∏–∫–ª –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {topic}")
                        result = await self.explore_topic(topic)
                        self._display_exploration(result)
                    else:
                        print("‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ —Ç–µ–º—É")
                else:
                    print(f"‚ùì –í–æ–ø—Ä–æ—Å: {user_input}")
                    result = await self.ask_question(user_input)
                    self._display_answer(result)
            except KeyboardInterrupt:
                print("\nüëã –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                break
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º —Ä–µ–∂–∏–º–µ: {e}")
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

    # ---------- –ú–µ—Ç–æ–¥—ã –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è ----------
    def _display_answer(self, result: dict):
        if 'error' in result:
            print(f"\n‚ùå –û—à–∏–±–∫–∞: {result['error']}")
            return

        profile = result.get('profile', '')
        key_facts_metadata = result.get('key_facts_metadata', [])
        query = result.get('query', '')

        from appp.utils.response_templates import RESPONSE_TEMPLATES, format_rich_response

        if profile and key_facts_metadata and profile in RESPONSE_TEMPLATES:
            try:
                template_data = self.analyst._prepare_template_data(profile, key_facts_metadata, query)
                logger.info(f"PROFILE: {profile}, METADATA COUNT: {len(key_facts_metadata)}")
                formatted = format_rich_response(profile, template_data)
                print("\n" + "‚úÖ" * 40)
                print(f"ü§ñ –û–¢–í–ï–¢ (–∏—Å—Ç–æ—á–Ω–∏–∫: {result.get('source', 'unknown')})")
                print("‚úÖ" * 40)
                print(f"\n{formatted}\n")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —à–∞–±–ª–æ–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}", exc_info=True)
                self._display_fallback_answer(result)
        else:
            self._display_fallback_answer(result)

        if 'confidence' in result:
            print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.1%}")
        if 'processing_time' in result:
            print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {result['processing_time']:.2f} —Å–µ–∫")
        if 'sources' in result and result['sources']:
            print("\nüîó –ò—Å—Ç–æ—á–Ω–∏–∫–∏:")
            for i, src in enumerate(result['sources'][:3], 1):
                print(f"   {i}. {src}")
        print("\n" + "‚úÖ" * 40)

    def _display_fallback_answer(self, result: dict):
        print("\n" + "‚úÖ" * 40)
        print(f"ü§ñ –û–¢–í–ï–¢ (–∏—Å—Ç–æ—á–Ω–∏–∫: {result.get('source', 'unknown')})")
        print("‚úÖ" * 40)
        answer = result.get('answer', result.get('synthesis', '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞'))
        print(f"\n{answer}\n")

    def _display_research(self, result: dict):
        if 'error' in result:
            print(f"\n‚ùå –û—à–∏–±–∫–∞: {result['error']}")
            return
        print("\n" + "üîç" * 40)
        print(f"üìö –†–ï–ó–£–õ–¨–¢–ê–¢ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø: {result.get('topic', '')}")
        print("üîç" * 40)
        if 'synthesis' in result:
            print(f"\n{result['synthesis']}\n")
        if 'key_findings' in result:
            print("üéØ –ö–ª—é—á–µ–≤—ã–µ –Ω–∞—Ö–æ–¥–∫–∏:")
            for i, finding in enumerate(result['key_findings'][:5], 1):
                print(f"   {i}. {finding}")
        if 'sources_used' in result:
            print(f"\nüìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {result['sources_used']}")
            print(f"üìà –ì–ª—É–±–∏–Ω–∞: {result.get('depth_achieved', 'N/A')}")
        print("\n" + "üîç" * 40)

    def _display_exploration(self, result: dict):
        if 'error' in result:
            print(f"\n‚ùå –û—à–∏–±–∫–∞: {result['error']}")
            return
        print("\n" + "üåÄ" * 40)
        print(f"üîÑ –¶–ò–ö–õ –ö–û–û–†–î–ò–ù–ê–¢: {result.get('topic', '')}")
        print("üåÄ" * 40)
        print(f"\n‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ —Ü–∏–∫–ª–æ–≤: {result.get('cycles_completed', 0)}")
        print(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {result.get('knowledge_chunks', 0)}")
        if 'synthesis' in result:
            print(f"\nüìã –°–∏–Ω—Ç–µ–∑:\n{result['synthesis']}\n")
        if 'key_insights' in result:
            print("üí° –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã:")
            for i, insight in enumerate(result['key_insights'][:5], 1):
                print(f"   {i}. {insight}")
        print("\n" + "üåÄ" * 40)

    def _display_status(self, status: dict):
        print("\n" + "üìä" * 40)
        print("–°–û–°–¢–û–Ø–ù–ò–ï –°–ò–°–¢–ï–ú–´")
        print("üìä" * 40)
        if not status.get('initialized'):
            print("‚ùå –°–∏—Å—Ç–µ–º–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            return
        uptime = status.get('uptime_seconds', 0)
        hours = int(uptime // 3600)
        minutes = int((uptime % 3600) // 60)
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {hours}—á {minutes}–º–∏–Ω")
        print(f"‚ùì –í–æ–ø—Ä–æ—Å–æ–≤: {status['session']['questions_asked']}")
        print(f"üîç –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π: {status['session']['research_done']}")
        print(f"üß† –¶–∏–∫–ª–æ–≤ –æ–±—É—á–µ–Ω–∏—è: {status['session']['learning_cycles']}")
        coord = status.get('coordinator', {})
        print(f"\nüéØ –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä:")
        print(f"   ‚Ä¢ –ó–∞–¥–∞—á –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {coord.get('tasks_processed', 0)}")
        print(f"   ‚Ä¢ –û—á–µ—Ä–µ–¥—å: {coord.get('queue_size', 0)}")
        print(f"   ‚Ä¢ –£—Ç–∏–ª–∏–∑–∞—Ü–∏—è: {coord.get('worker_utilization', 0):.1%}")
        chroma = status.get('chroma', {})
        print(f"\nüíæ ChromaDB:")
        print(f"   ‚Ä¢ –ó–∞–ø–∏—Å–µ–π: {chroma.get('collection_size', 0)}")
        print(f"   ‚Ä¢ –•–∏—Ç—ã –∫—ç—à–∞: {chroma.get('cache_hit_rate', 0):.1%}")
        graph = status.get('graph', {})
        print(f"\nüï∏Ô∏è  –ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π:")
        print(f"   ‚Ä¢ –£–∑–ª–æ–≤: {graph.get('nodes', 0)}")
        print(f"   ‚Ä¢ –°–≤—è–∑–µ–π: {graph.get('edges', 0)}")
        engram = status.get('engram', {})
        print(f"\nüß† Engram –ø–∞–º—è—Ç—å:")
        print(f"   ‚Ä¢ –ó–∞–ø–∏—Å–µ–π: {engram.get('total_records', 0)}")
        print(f"   ‚Ä¢ –•–∏—Ç—ã: {engram.get('hit_rate', 0):.1%}")
        if 'learning' in status:
            learning = status['learning']
            print(f"\nüß† –°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ:")
            print(f"   ‚Ä¢ –í–∫–ª—é—á–µ–Ω–æ: {learning.get('enabled', False)}")
            print(f"   ‚Ä¢ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–π: {learning.get('total_executions', 0)}")
            for cycle, stats in learning.get('cycle_stats', {}).items():
                print(f"      {cycle}: –≤—ã–ø–æ–ª–Ω–µ–Ω–æ {stats.get('executions', 0)}")
        print("\n" + "üìä" * 40)

    def _display_detailed_stats(self, status: dict):
        self._display_status(status)
        committee = status.get('committee', {})
        print(f"\n‚öñÔ∏è  –ö–æ–º–∏—Ç–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞:")
        print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–æ–∫: {committee.get('evaluations', 0)}")
        print(f"   ‚Ä¢ –û–¥–æ–±—Ä–µ–Ω–æ: {committee.get('approved', 0)} ({committee.get('approval_rate', 0):.1%})")
        analyst = status.get('analyst', {})
        print(f"\nüìö –ê–Ω–∞–ª–∏—Ç–∏–∫:")
        print(f"   ‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {analyst.get('documents_processed', 0)}")
        print(f"   ‚Ä¢ –ß–∞–Ω–∫–æ–≤: {analyst.get('chunks_created', 0)}")
        embedder = status.get('embedder', {})
        print(f"\nüß† –≠–º–±–µ–¥–¥–∏–Ω–≥–∏:")
        print(f"   ‚Ä¢ –ö—ç—à: {embedder.get('cache_size', 0)} –∑–∞–ø–∏—Å–µ–π")
        print(f"   ‚Ä¢ –•–∏—Ç—ã: {embedder.get('cache_hit_rate', 0):.1%}")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {embedder.get('avg_embedding_time', 0):.3f} —Å–µ–∫")

    async def cleanup(self):
        logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã...")
        if self.learning_task:
            self.learning_task.cancel()
            try:
                await self.learning_task
            except asyncio.CancelledError:
                pass
        if self.learning_coordinator:
            self.learning_coordinator.stop()
        if self.coordinator:
            await self.coordinator.shutdown()
        if self.chroma_db:
            await self.chroma_db.close()
        if self.graph_db:
            await self.graph_db.close()
        if self.engram:
            await self.engram.close()
        if self.detective:
            await self.detective.cleanup()
        if self.embedder:
            await self.embedder.close()
        logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞ —Ä–∞–±–æ—Ç—É")
        print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")


async def main():
    print("\n" + "üöÄ" * 80)
    print(" AUTONOMOUS AI PRODUCTION READY SYSTEM v3.1 ")
    print(" –ü–æ–ª–Ω–æ—Å—Ç—å—é –ª–æ–∫–∞–ª—å–Ω–∞—è, —Å Engram –ø–∞–º—è—Ç—å—é, BGE-M3, NER –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º ")
    print("üöÄ" * 80)

    log_file = './data/logs/autonomous_ai.log'
    os.makedirs(os.path.dirname(log_file), exist_ok=True)
    setup_logging(log_level='INFO', log_file=log_file, use_detailed_format=False)

    ai = AutonomousAIPro(config_path='./configs/production.yaml')

    try:
        success = await ai.initialize()
        if not success:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É")
            print("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏.")
            return
        await ai.interactive_mode()
    except KeyboardInterrupt:
        print("\n\nüëã –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    except Exception as e:
        logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        print(f"\n‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        traceback.print_exc()
    finally:
        await ai.cleanup()


if __name__ == "__main__":
    if sys.version_info < (3, 8):
        print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è Python 3.8 –∏–ª–∏ –≤—ã—à–µ")
        sys.exit(1)
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        traceback.print_exc()