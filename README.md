# hybrid-ai-core
Hybrid AI system with Production Assistant and Self-Learning Core using Engram Graph Memory (NetworkX)

---

# ğŸ¤– Hybrid AI System

[Ğ Ğ£Ğ¡] / [ENG]

---

## ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹

### ğŸ“¦ Ğ¡Ğ¾ÑÑ‚Ğ°Ğ² Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

#### ğŸ¯ Production Assistant (`/app`) â€” **Ğ“ĞĞ¢ĞĞ’Ğ Ğš Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞ˜Ğ®**
ĞŸÑ€Ğ¾Ğ´Ğ°ĞºÑˆĞµĞ½-Ğ²ĞµÑ€ÑĞ¸Ñ AI Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ°:
- FastAPI + async SQLAlchemy
- Ğ§Ğ°Ñ‚ Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸ĞµĞ¹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²
- Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ±Ğ°Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ (ChromaDB)
- Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ÑĞ²ÑĞ·Ğ¸ Ğ¸ RL Ğ°Ğ³ĞµĞ½Ñ‚
- A/B Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²
- Prometheus Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
- Streamlit Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ

#### ğŸ§  Self-Learning Core (`/autonomous_ai`) â€” **Ğ’ Ğ ĞĞ—Ğ ĞĞ‘ĞĞ¢ĞšĞ•**
Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ´Ñ€Ğ¾ Ñ Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒÑ (Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚, Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ):
- Engram Graph Memory (NetworkX)
- Ğ”Ğ¾Ğ»Ğ³Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ (Engram DB)
- Knowledge Analyst â€” Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹
- Quality Committee â€” Ğ¾Ñ†ĞµĞ½ĞºĞ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
- Detective â€” Ğ¿Ğ¾Ğ¸ÑĞº Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ
- BGE-M3 ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸
- Question Generator â€” Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²

> âš¡ Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚, Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾Ğ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ.

### ğŸš€ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚

```bash
# ĞšĞ»Ğ¾Ğ½Ğ¸Ñ€ÑƒĞµĞ¼
git clone https://github.com/yourname/hybrid-ai-core
cd hybrid-ai-core

# Ğ’Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
python -m venv venv
source venv/bin/activate  # Ğ¸Ğ»Ğ¸ venv\Scripts\activate Ğ½Ğ° Windows

# Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
pip install -r app/requirements.txt

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°
cp .env.example .env
# ĞÑ‚Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ .env Ğ¿Ğ¾Ğ´ ÑĞ²Ğ¾Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹

# Ğ—Ğ°Ğ¿ÑƒÑĞº API
cd app
python main.py

ğŸ“š API Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ

ĞŸĞ¾ÑĞ»Ğµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°:

    Swagger UI: http://localhost:8000/docs

    ReDoc: http://localhost:8000/redoc

ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹
ĞœĞµÑ‚Ğ¾Ğ´	Endpoint	ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ
POST	/api/v1/chat/ask	Ğ—Ğ°Ğ´Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ
POST	/api/v1/knowledge/add	Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ
GET	/api/v1/knowledge/search	ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ·Ğ½Ğ°Ğ½Ğ¸ÑĞ¼
POST	/api/v1/feedback	ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ·Ñ‹Ğ²
GET	/api/v1/system/health	ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ
GET	/api/v1/system/metrics	ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Prometheus
ğŸ“Š ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³

    ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸: http://localhost:8000/api/v1/system/metrics

    Health check: http://localhost:8000/api/v1/system/health

    Streamlit Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´:
    bash

    streamlit run streamlit_apps/monitor_app.py

    Streamlit Ñ‡Ğ°Ñ‚:
    bash

    streamlit run streamlit_apps/chat_app.py

ğŸ³ Docker
bash

# Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²ÑĞµÑ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
docker-compose -f deployments/production/docker-compose.dev.yml up -d

# ĞŸÑ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ Ğ»Ğ¾Ğ³Ğ¾Ğ²
docker-compose -f deployments/production/docker-compose.dev.yml logs -f

ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
text

.
â”œâ”€â”€ app/                    # Production Assistant (Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾)
â”‚   â”œâ”€â”€ api/               # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ FastAPI
â”‚   â”œâ”€â”€ core/              # Ğ¯Ğ´Ñ€Ğ¾ (brain, config)
â”‚   â”œâ”€â”€ infrastructure/     # Ğ‘Ğ”, ĞºÑÑˆ
â”‚   â”œâ”€â”€ services/          # Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ»Ğ¾Ğ³Ğ¸ĞºĞ°
â”‚   â””â”€â”€ monitoring/        # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸, Ñ…ĞµĞ»ÑÑ‡ĞµĞºĞ¸
â”‚
â”œâ”€â”€ autonomous_ai/          # Self-Learning Core (Ğ² Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ) ğŸš§
â”‚   â”œâ”€â”€ appp/
â”‚   â”‚   â”œâ”€â”€ coordination/  # ĞšĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ²
â”‚   â”‚   â”œâ”€â”€ services/      # Ğ¡ĞµÑ€Ğ²Ğ¸ÑÑ‹ Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ
â”‚   â”‚   â””â”€â”€ utils/         # Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹
â”‚   â””â”€â”€ configs/           # YAML ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¸
â”‚
â”œâ”€â”€ streamlit_apps/         # Ğ¤Ñ€Ğ¾Ğ½Ñ‚ĞµĞ½Ğ´
â”œâ”€â”€ deployments/            # Docker ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ñ‹
â””â”€â”€ tests/                  # Ğ¢ĞµÑÑ‚Ñ‹

âš™ï¸ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ

ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ² .env:
env

DATABASE_URL=postgresql://user:pass@localhost:5432/ai_core
REDIS_URL=redis://localhost:6379/0
CHROMA_HOST=localhost
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2

ğŸ‡¬ğŸ‡§ English
ğŸ“¦ Project Structure
ğŸ¯ Production Assistant (/app) â€” PRODUCTION READY

Production-ready AI assistant:

    FastAPI + async SQLAlchemy

    Chat with conversation history

    Vector knowledge base (ChromaDB)

    Feedback system with RL agent

    A/B testing for responses

    Prometheus metrics

    Streamlit interface

ğŸ§  Self-Learning Core (/autonomous_ai) â€” IN DEVELOPMENT

Experimental core with graph memory (working, you can test):

    Engram Graph Memory (NetworkX)

    Long-term memory (Engram DB)

    Knowledge Analyst

    Quality Committee

    Detective (web search)

    BGE-M3 embeddings

    Question Generator

    âš¡ Basic functionality works, currently polishing and optimizing.

ğŸš€ Quick Start
bash

# Clone
git clone https://github.com/yourname/hybrid-ai-core
cd hybrid-ai-core

# Virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r app/requirements.txt

# Configuration
cp .env.example .env
# Edit .env with your settings

# Run API
cd app
python main.py

ğŸ“š API Documentation

After starting:

    Swagger UI: http://localhost:8000/docs

    ReDoc: http://localhost:8000/redoc

Main Endpoints
Method	Endpoint	Description
POST	/api/v1/chat/ask	Ask a question
POST	/api/v1/knowledge/add	Add knowledge
GET	/api/v1/knowledge/search	Search knowledge
POST	/api/v1/feedback	Submit feedback
GET	/api/v1/system/health	Health check
GET	/api/v1/system/metrics	Prometheus metrics
ğŸ“Š Monitoring

    Metrics: http://localhost:8000/api/v1/system/metrics

    Health check: http://localhost:8000/api/v1/system/health

    Streamlit dashboard:
    bash

    streamlit run streamlit_apps/monitor_app.py

    Streamlit chat:
    bash

    streamlit run streamlit_apps/chat_app.py

ğŸ³ Docker
bash

# Start all services
docker-compose -f deployments/production/docker-compose.dev.yml up -d

# View logs
docker-compose -f deployments/production/docker-compose.dev.yml logs -f

ğŸ“ Project Structure
text

.
â”œâ”€â”€ app/                    # Production Assistant (ready)
â”‚   â”œâ”€â”€ api/               # FastAPI endpoints
â”‚   â”œâ”€â”€ core/              # Brain, config
â”‚   â”œâ”€â”€ infrastructure/     # DB, cache
â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â””â”€â”€ monitoring/        # Metrics, health checks
â”‚
â”œâ”€â”€ autonomous_ai/          # Self-Learning Core (WIP) ğŸš§
â”‚   â”œâ”€â”€ appp/
â”‚   â”‚   â”œâ”€â”€ coordination/  # Service coordinator
â”‚   â”‚   â”œâ”€â”€ services/      # Core services
â”‚   â”‚   â””â”€â”€ utils/         # Utilities
â”‚   â””â”€â”€ configs/           # YAML configs
â”‚
â”œâ”€â”€ streamlit_apps/         # Frontend
â”œâ”€â”€ deployments/            # Docker compose
â””â”€â”€ tests/                  # Tests

âš™ï¸ Configuration

Main environment variables in .env:
env

DATABASE_URL=postgresql://user:pass@localhost:5432/ai_core
REDIS_URL=redis://localhost:6379/0
CHROMA_HOST=localhost
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2

ğŸ“„ License

Apache License 2.0
ğŸ‘¨ğŸ’» Author

Jin V - initial work

â­ Star this repo if you find it useful!
ğŸ’» Dev Environment Note

The entire stack (Assistant + Self-Learning Core) is currently being developed and tested on an old laptop inside a virtual machine. This seriously limits the speed of graph memory (Engram) training and RL agent performance.

If you like the architecture and want to help move the project from an old laptop to proper hardware for full-scale neural network experiments â€” I'd be truly grateful for your support!

Support the transition to Bare Metal:

BTC: 13qEwAA1JK3f5zkt51DpM63DmgPwznUkom
TON: UQBIr6VL-S6o5pNr7JcsyhYH0SNOUilLIV2kBaqb3EifupPp
**MEMO (REQUIRED):** 3EifupPp
